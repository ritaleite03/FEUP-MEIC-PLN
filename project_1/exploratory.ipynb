{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 - Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_uk_train = pd.read_json(\"data/reddit-uk-train.jsonl\", lines=True, encoding=\"utf-8\").drop(\"id\", axis=1)\n",
    "reddit_in_train = pd.read_json(\"data/reddit-in-train.jsonl\", lines=True, encoding=\"utf-8\").drop(\"id\", axis=1)\n",
    "reddit_au_train = pd.read_json(\"data/reddit-au-train.jsonl\", lines=True, encoding=\"utf-8\").drop(\"id\", axis=1)\n",
    "reddit_uk_valid = pd.read_json(\"data/reddit-uk-valid.jsonl\", lines=True, encoding=\"utf-8\").drop(\"id\", axis=1)\n",
    "reddit_in_valid = pd.read_json(\"data/reddit-in-valid.jsonl\", lines=True, encoding=\"utf-8\").drop(\"id\", axis=1)\n",
    "reddit_au_valid = pd.read_json(\"data/reddit-au-valid.jsonl\", lines=True, encoding=\"utf-8\").drop(\"id\", axis=1)\n",
    "\n",
    "google_uk_train = pd.read_json(\"data/google-uk-train.jsonl\", lines=True, encoding=\"utf-8\").drop(\"id\", axis=1)\n",
    "google_in_train = pd.read_json(\"data/google-in-train.jsonl\", lines=True, encoding=\"utf-8\").drop(\"id\", axis=1)\n",
    "google_au_train = pd.read_json(\"data/google-au-train.jsonl\", lines=True, encoding=\"utf-8\").drop(\"id\", axis=1)\n",
    "google_uk_valid = pd.read_json(\"data/google-uk-valid.jsonl\", lines=True, encoding=\"utf-8\").drop(\"id\", axis=1)\n",
    "google_in_valid = pd.read_json(\"data/google-in-valid.jsonl\", lines=True, encoding=\"utf-8\").drop(\"id\", axis=1)\n",
    "google_au_valid = pd.read_json(\"data/google-au-valid.jsonl\", lines=True, encoding=\"utf-8\").drop(\"id\", axis=1)\n",
    "\n",
    "reddit_uk_union = pd.concat([reddit_uk_train, reddit_uk_valid], ignore_index=True)\n",
    "reddit_au_union = pd.concat([reddit_au_train, reddit_au_valid], ignore_index=True)\n",
    "reddit_in_union = pd.concat([reddit_in_train, reddit_in_valid], ignore_index=True)\n",
    "\n",
    "google_uk_union = pd.concat([google_uk_train, google_uk_valid], ignore_index=True)\n",
    "google_au_union = pd.concat([google_au_train, google_au_valid], ignore_index=True)\n",
    "google_in_union = pd.concat([google_in_train, google_in_valid], ignore_index=True)\n",
    "\n",
    "print(\"Reddit uk : train = \" + str(len(reddit_uk_train)) + \", valid = \" + str(len(reddit_uk_valid)) + \" and union \" + str(len(reddit_uk_union)))\n",
    "print(\"Reddit au : train = \" + str(len(reddit_au_train)) + \", valid = \" + str(len(reddit_au_valid)) + \" and union \" + str(len(reddit_au_union)))\n",
    "print(\"Reddit in : train = \" + str(len(reddit_in_train)) + \", valid = \" + str(len(reddit_in_valid)) + \" and union \" + str(len(reddit_in_union)))\n",
    "print(\"Google uk : train = \" + str(len(google_uk_train)) + \", valid = \" + str(len(google_uk_valid)) + \" and union \" + str(len(google_uk_union)))\n",
    "print(\"Google au : train = \" + str(len(google_au_train)) + \", valid = \" + str(len(google_au_valid)) + \" and union \" + str(len(google_au_union)))\n",
    "print(\"Google in : train = \" + str(len(google_in_train)) + \", valid = \" + str(len(google_in_valid)) + \" and union \" + str(len(google_in_union)))\n",
    "\n",
    "uk_union = pd.concat([reddit_uk_union, google_uk_union], ignore_index=True)\n",
    "au_union = pd.concat([reddit_au_union, google_au_union], ignore_index=True)\n",
    "in_union = pd.concat([reddit_in_union, google_in_union], ignore_index=True)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"All uk : \" + str(len(uk_union)))\n",
    "print(\"All au : \" + str(len(au_union)))\n",
    "print(\"All in : \" + str(len(in_union)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Comparing Language and Platform\n",
    "By analyzing the graph below, it is evident that the Reddit datasets predominantly contain negative comments, regardless of the country. In contrast, the Google datasets are mostly positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [reddit_uk_union, google_uk_union, reddit_au_union, google_au_union, reddit_in_union, google_in_union]\n",
    "labels = [\"Reddit UK\", \"Google UK\", \"Reddit AU\", \"Google AU\", \"Reddit IN\", \"Google IN\"]\n",
    "colors = [\"blue\", \"orange\", \"green\", \"red\", \"purple\", \"brown\"]\n",
    "\n",
    "counts = [df[\"sentiment_label\"].value_counts() for df in datasets]\n",
    "all_labels = sorted(set().union(*[count.index for count in counts]))\n",
    "\n",
    "x = np.arange(len(all_labels))\n",
    "width = 0.12  \n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for i, (count, label, color) in enumerate(zip(counts, labels, colors)):\n",
    "    valores = [count.get(cat, 0) for cat in all_labels]\n",
    "    plt.bar(x + i * width - (width * 2.5), valores, width=width, label=label, color=color)\n",
    "\n",
    "plt.xticks(x, all_labels)\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Comparing Sentiment Labels\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Comparing Language\n",
    "\n",
    "When analyzing the graph below, it appears that the datasets are relatively balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [uk_union, au_union, in_union]\n",
    "labels = [\"UK\", \"AU\", \"IN\"]\n",
    "colors = [\"blue\", \"orange\", \"green\"]\n",
    "\n",
    "counts = [df[\"sentiment_label\"].value_counts() for df in datasets]\n",
    "all_labels = sorted(set().union(*[count.index for count in counts]))\n",
    "\n",
    "x = np.arange(len(all_labels))\n",
    "width = 0.12  \n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "for i, (count, label, color) in enumerate(zip(counts, labels, colors)):\n",
    "    valores = [count.get(cat, 0) for cat in all_labels]\n",
    "    plt.bar(x + i * width - (width * 2.5), valores, width=width, label=label, color=color)\n",
    "\n",
    "plt.xticks(x, all_labels)\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Comparing Sentiment Labels\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
